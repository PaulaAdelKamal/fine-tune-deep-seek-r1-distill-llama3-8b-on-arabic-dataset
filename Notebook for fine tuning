{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:02:54.352155Z","iopub.execute_input":"2025-03-27T15:02:54.352442Z","iopub.status.idle":"2025-03-27T15:06:35.475716Z","shell.execute_reply.started":"2025-03-27T15:02:54.352422Z","shell.execute_reply":"2025-03-27T15:06:35.474444Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"hf\")\nlogin(hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:06:47.504221Z","iopub.execute_input":"2025-03-27T15:06:47.504588Z","iopub.status.idle":"2025-03-27T15:06:48.579707Z","shell.execute_reply.started":"2025-03-27T15:06:47.504562Z","shell.execute_reply":"2025-03-27T15:06:48.578834Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import wandb\n\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on Medical COT Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:06:51.021471Z","iopub.execute_input":"2025-03-27T15:06:51.021763Z","iopub.status.idle":"2025-03-27T15:07:06.217781Z","shell.execute_reply.started":"2025-03-27T15:06:51.021742Z","shell.execute_reply":"2025-03-27T15:07:06.217144Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpakks\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250327_150700-5ezkx49g</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/5ezkx49g' target=\"_blank\">electric-wave-3</a></strong> to <a href='https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset' target=\"_blank\">https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/5ezkx49g' target=\"_blank\">https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/5ezkx49g</a>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from unsloth import FastLanguageModel\n\nmax_seq_length = 2048 \ndtype = None \nload_in_4bit = True\n\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    token = hf_token, \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:07:07.518918Z","iopub.execute_input":"2025-03-27T15:07:07.519195Z","iopub.status.idle":"2025-03-27T15:08:21.919888Z","shell.execute_reply.started":"2025-03-27T15:07:07.519175Z","shell.execute_reply":"2025-03-27T15:08:21.919166Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n🦥 Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"107d13d3b9554898aace11881219d7c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d8a7e9d03d94062abb9e0d85608cd56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e5b5dd5e3b942b286e73a5012074b58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1bd8211373145d594296c9eb20676e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4d3ba4351814d55b2bfbaf93b808a0f"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nyou are a helpfull agent\n\n### Question:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:12:10.890376Z","iopub.execute_input":"2025-03-27T15:12:10.890718Z","iopub.status.idle":"2025-03-27T15:12:10.895186Z","shell.execute_reply.started":"2025-03-27T15:12:10.890694Z","shell.execute_reply":"2025-03-27T15:12:10.894551Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"question = \"اكتب قصة من 500 كلمة من وجهة نظر الشخص الثالث ، عن فتاة مراهقة تدعى ليلي ، التي تكتشف أنها يمكنها إنشاء حقول قوة ولكنها تكافح للسيطرة على قوتها ، استخدم اللغة الحسية والصور الحية لوصف تجارب ليلي أثناء التنقل بقدراتها الجديدة والعواقب التي تأتي معها.\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:12:12.154796Z","iopub.execute_input":"2025-03-27T15:12:12.155073Z","iopub.status.idle":"2025-03-27T15:13:30.536056Z","shell.execute_reply.started":"2025-03-27T15:12:12.155053Z","shell.execute_reply":"2025-03-27T15:13:30.535122Z"}},"outputs":[{"name":"stdout","text":"\nAlright, I need to help the user by writing a 500-word story from a third-person perspective about a young girl named Layla who discovers she can create power fields but struggles to control her power. I should use sensory and vivid descriptions to describe Layla's experiences during her journey with her new abilities and the consequences that come with them.\n\nFirst, I'll set the scene to establish a sense of mystery and wonder. Maybe Layla is walking through a forest at night, feeling something different in the air. I'll describe the sights, sounds, and feelings she experiences as she comes into contact with the energy field.\n\nNext, I need to introduce how she discovers her ability. Perhaps she touches an object that reacts strangely, or she sees a glowing light. I'll make sure to describe her emotions and physical reactions to this discovery.\n\nThen, I'll show her initial attempts to control the power. Maybe she tries using it to help someone, but things go wrong, leading to unintended consequences. This will highlight her struggle and the challenges she faces as she learns to manage her power.\n\nI should also include some conflict. Maybe she meets another person with similar abilities, leading to a rivalry or a quest for knowledge. This can add depth to her story and provide a backdrop for her growth.\n\nThroughout the story, I'll use sensory details to make the scenes vivid. Descriptions of the environment, her physical sensations, and her emotional state will help the reader connect with her experiences.\n\nFinally, I'll conclude with Layla understanding the responsibility that comes with her power and perhaps a hint of the journey ahead. I'll make sure the story has a satisfying ending, showing her growth and the new direction her life is taking.\n\nI need to ensure the language is descriptive and engaging, keeping the reader interested throughout the 500 words. I'll also make sure the story flows logically, with each paragraph leading smoothly to the next.\n\nOkay, I think I have a good plan. I'll start writing the story, making sure to incorporate all these elements to create an engaging and vivid narrative about Layla's journey with her power.\n</think>\n\nليلة، الفتاة المراهقة، كانت ت漫طق في الغابة المظلمة، مع عينين مليئتين بالدخوذ والارتباك. الرياح كانت ترفرف حولها، وآذيتها كانت مليئة بالهبوب والكشيش، لكنها لم تلاحظ ما إذا كانت تلك الأصوات عادية أم متعددة. في تلك الليلة، ليلة لم تكن عاديةً على الإطلاق.\n\nحسب عاداتها، ليلة كانت تذهب إلى الغابة كل ليلة، للبحث عن الأشياء المفقودة أو للترطيب من العشب المر، لكن هذا المساء كان مختلفًا. عندما بدأت تتنفس بعمق، فكشفت أن空气 كانت ممتلئة بوعلاً مريبًا، لكنها لم تكن في استطاعة التفسير. ثم، وهي تقرب إلى شجرة مظلمة، فكشفت أن هناك إشعاعًا خافتًا في الهواء، مثلنور مضيئ في الليل.\n\nليلة لم تكن تتصرف عادةً بذلك، لكنها شعرت أن عقلها كان يؤلم من ذلك الإشعاع. فلمحرت حولها، فكشفت أن هناك شيء ما يحرك في الهواء، وانهال إليها. لقد بدت كأنها كانت تلامس الحبشة، لكنها لم تلمس شيئًا. بدلاً من ذلك، فكشفت أن هناك إحساسًا ممتعًا، مثللمسة لطيفة على جلدها.\n\nأحلى من ذلك، ليلة لم تكن تتصرف عاديةً. فلمحرت أن هناك شيء ما يتصرف معها، فحاولت التفاعل. لقد أصبحت ليلة متماسكةً، مع عقلها ممتلأ بالحواس. فكشفت أن هناك قوة في الهواء، قوة يمكنها أن تتحكم بها. لقد بدت كأنها كانت تلمس الحقول، لكنها لم تلمس شيئًا. بدلاً من ذلك، فكشفت أن هناك إحساسًا ممتعًا، مثللمسة لطيفة على جلدها.\n\nأحلى من ذلك، ليلة لم تكن تتصرف عاديةً. فلمحرت أن هناك شيء ما يتصرف معها، فحاولت التفاعل. لقد أصبحت ليلة متماسكةً، مع عقلها ممتلأ بالحواس. فكشفت أن هناك قوة في الهواء، قوة يمكنها أن تتحكم بها. لقد بدت كأنها كانت تلمس الحقول، لكنها لم تلمس شيئًا. بدلاً من ذلك، فكشفت أن هناك إحساسًا ممتعًا، مثللمسة لطيفة على جلدها.\n\nأحلى من ذلك، ليلة لم تكن تتصرف عاديةً. فلمحرت أن هناك شيء ما يتصرف معها، فحاولت التفاعل. لقد أصبحت ليلة متماسكةً، مع عقلها ممتلأ بالحواس. فكشفت أن هناك قوة في الهواء، قوة يمكنها أن تتحكم بها. لقد بدت كأنها كانت تلمس الحقول، لكنها لم تلمس شيئًا. بدلاً من ذلك، فكشفت أن هناك إحساسًا ممتعًا، مثل\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nyou are a helpful agent speaking arabic that uses reasoning.\n### Question:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:20.566970Z","iopub.execute_input":"2025-03-27T16:22:20.567334Z","iopub.status.idle":"2025-03-27T16:22:20.572218Z","shell.execute_reply.started":"2025-03-27T16:22:20.567306Z","shell.execute_reply":"2025-03-27T16:22:20.571302Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n\n\ndef formatting_prompts_func(examples):\n    inputs = examples[\"prompt\"]\n    outputs = examples[\"response\"]\n    texts = []\n    for input, output in zip(inputs, outputs):\n        text = train_prompt_style.format(input, output) + EOS_TOKEN\n        texts.append(text)\n    return {\n        \"text\": texts,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:24.224367Z","iopub.execute_input":"2025-03-27T16:22:24.224718Z","iopub.status.idle":"2025-03-27T16:22:24.230727Z","shell.execute_reply.started":"2025-03-27T16:22:24.224691Z","shell.execute_reply":"2025-03-27T16:22:24.229850Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"maanasharma5/arabic_sft_data\", split = \"train[0:5000]\",trust_remote_code=True)\ndataset = dataset.map(formatting_prompts_func, batched = True,)\ndataset[\"text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:26.689110Z","iopub.execute_input":"2025-03-27T16:22:26.689509Z","iopub.status.idle":"2025-03-27T16:22:27.853393Z","shell.execute_reply.started":"2025-03-27T16:22:26.689467Z","shell.execute_reply":"2025-03-27T16:22:27.852571Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"433b58e3bfcf4a2fa097201801202eec"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nyou are a helpful agent speaking arabic that uses reasoning.\\n### Question:\\nاكتب قصة من 500 كلمة من وجهة نظر الشخص الثالث ، عن فتاة مراهقة تدعى ليلي ، التي تكتشف أنها يمكنها إنشاء حقول قوة ولكنها تكافح للسيطرة على قوتها ، استخدم اللغة الحسية والصور الحية لوصف تجارب ليلي أثناء التنقل بقدراتها الجديدة والعواقب التي تأتي معها.\\n\\n### Response:\\nكانت ليلي دائمًا مراهقة متوسطة ، تتصارع مع صعوبات وآثار المراهقة ، لكن في يوم من الأيام ، أثناء المشي مع كلبها ، تعثرت على كائن غريب سقط من السماء ، وقامت بتصويره ، وشعرت بالخوف من عدم سيطرتها عليه ، فقدت الصبر على ما فعلته ، وابتسمت ، وشعرت بالخوف من عدم قدرتها على التحكم به ، وابتسمت ، وابتسمت ، وابتسمت ، وابتسمت ، وابتسمت ، وابتسمت ، وابتسمت ، وابتسمت ، وأبتسمت ، وأبتسمت ، وأبتسمت ، وأبتسمت ، وأبتسمت ، وأبتسمت ،بتسمت ،بتسمت ،بتسمت ،بتسمت ،بتسمت ،بت ،بتسمت ،بت ،بتسمت ،بت ،بتسمت ،بت ،بتسمت ،بت ،بتسمت ،بت ،بتسمبت ،بت ،بتسمبت ،بت ،بتسمبت ،بت ،بتسمبت ،بت ،بتسمبت ،بت ،بتسمبت ،بت ،<｜end▁of▁sentence｜>'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  \n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n    ],\n    lora_alpha=16,\n    lora_dropout=0,  \n    bias=\"none\",  \n    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n    random_state=3407,\n    use_rslora=False,  \n    loftq_config=None,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:36.000815Z","iopub.execute_input":"2025-03-27T16:22:36.001122Z","iopub.status.idle":"2025-03-27T16:22:36.010679Z","shell.execute_reply.started":"2025-03-27T16:22:36.001099Z","shell.execute_reply":"2025-03-27T16:22:36.009590Z"}},"outputs":[{"name":"stderr","text":"Unsloth: Already have LoRA adapters! We shall skip this step.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    args=TrainingArguments(\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=4,\n        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n        warmup_steps=5,\n        max_steps=60,\n        learning_rate=2e-4,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        logging_steps=10,\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        output_dir=\"outputs\",\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:39.588776Z","iopub.execute_input":"2025-03-27T16:22:39.589109Z","iopub.status.idle":"2025-03-27T16:22:45.068401Z","shell.execute_reply.started":"2025-03-27T16:22:39.589085Z","shell.execute_reply":"2025-03-27T16:22:45.067570Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75dea91601104f2991726999ae9772d9"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:47.653139Z","iopub.execute_input":"2025-03-27T16:22:47.653567Z","iopub.status.idle":"2025-03-27T16:49:13.368852Z","shell.execute_reply.started":"2025-03-27T16:22:47.653531Z","shell.execute_reply":"2025-03-27T16:49:13.368108Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 5,000 | Num Epochs = 1 | Total steps = 60\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 25:56, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.704500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.421500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.468800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.520100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.468200</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.505900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"question = \"اكتب قصة من 500 كلمة من وجهة نظر الشخص الثالث ، عن فتاة مراهقة تدعى ليلي ، التي تكتشف أنها يمكنها إنشاء حقول قوة ولكنها تكافح للسيطرة على قوتها ، استخدم اللغة الحسية والصور الحية لوصف تجارب ليلي أثناء التنقل بقدراتها الجديدة والعواقب التي تأتي معها.\"\n\n\nFastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:49:13.370015Z","iopub.execute_input":"2025-03-27T16:49:13.370326Z","iopub.status.idle":"2025-03-27T16:50:40.660108Z","shell.execute_reply.started":"2025-03-27T16:49:13.370290Z","shell.execute_reply":"2025-03-27T16:50:40.658983Z"}},"outputs":[{"name":"stdout","text":"\nكانت ليلي تعاني من صداع مفرط ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك ، لكنها لم تكن متأكدة من ذلك\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"new_model_local = \"DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned\"\nmodel.save_pretrained(new_model_local) \ntokenizer.save_pretrained(new_model_local)\n\nmodel.save_pretrained_merged(new_model_local, tokenizer, save_method = \"merged_16bit\",)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:50:40.662007Z","iopub.execute_input":"2025-03-27T16:50:40.662394Z","iopub.status.idle":"2025-03-27T16:52:37.527711Z","shell.execute_reply.started":"2025-03-27T16:50:40.662361Z","shell.execute_reply":"2025-03-27T16:52:37.526928Z"}},"outputs":[{"name":"stderr","text":"Unsloth: You have 2 CPUs. Using `safe_serialization` is 10x slower.\nWe shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\nTo force `safe_serialization`, set it to `None` instead.\nUnsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\nmodel which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\nUnsloth: Will remove a cached repo with size 6.0G\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 18.49 out of 31.35 RAM for saving.\nUnsloth: Saving model... This might take 5 minutes ...\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 11/32 [00:00<00:01, 13.91it/s]\nWe will save to Disk and not RAM now.\n100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Saving tokenizer... Done.\nUnsloth: Saving DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00001-of-00004.bin...\nUnsloth: Saving DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00002-of-00004.bin...\nUnsloth: Saving DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00003-of-00004.bin...\nUnsloth: Saving DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00004-of-00004.bin...\nDone.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"new_model_online = \"Paula139/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned\"\nmodel.push_to_hub(new_model_online)\ntokenizer.push_to_hub(new_model_online)\n\nmodel.push_to_hub_merged(new_model_online, tokenizer, save_method = \"merged_16bit\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:52:37.535254Z","iopub.execute_input":"2025-03-27T16:52:37.535542Z","iopub.status.idle":"2025-03-27T16:58:43.707690Z","shell.execute_reply.started":"2025-03-27T16:52:37.535509Z","shell.execute_reply":"2025-03-27T16:58:43.706713Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d39dcdddeb464d8781ba8e3e40056258"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98c398cf97874da4a7a40754debf3e80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a62927d54c0241128ecc99d60907e00a"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/Paula139/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18c49a7c230d4923aa59ab3aee034ac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abbd04588d4f498895f98fa59614e77a"}},"metadata":{}},{"name":"stderr","text":"Unsloth: You are pushing to hub in Kaggle environment.\nTo save memory, we shall move Paula139/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned to /tmp/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned\nUnsloth: Will remove a cached repo with size 1.6K\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 17.8 out of 31.35 RAM for saving.\nUnsloth: Saving model... This might take 5 minutes ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Saving tokenizer... Done.\nUnsloth: Saving /tmp/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00001-of-00004.bin...\nUnsloth: Saving /tmp/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00002-of-00004.bin...\nUnsloth: Saving /tmp/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00003-of-00004.bin...\nUnsloth: Saving /tmp/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00004-of-00004.bin...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00003-of-00004.bin:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44d1c6f5e3b8427694acbf663696bacf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00004.bin:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4223361f886349a69587c4ad3e60c63d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"022ef232b2b242fba27c41a3ecf72eb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00004.bin:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b144cf3dae04e7ba382c20609c1f52a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00004-of-00004.bin:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbed6950f6f34bda9d3a65d4132f826b"}},"metadata":{}},{"name":"stdout","text":"Done.\nSaved merged model to https://huggingface.co/Paula139/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}