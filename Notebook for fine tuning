{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:02:54.352155Z","iopub.execute_input":"2025-03-27T15:02:54.352442Z","iopub.status.idle":"2025-03-27T15:06:35.475716Z","shell.execute_reply.started":"2025-03-27T15:02:54.352422Z","shell.execute_reply":"2025-03-27T15:06:35.474444Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"hf\")\nlogin(hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:06:47.504221Z","iopub.execute_input":"2025-03-27T15:06:47.504588Z","iopub.status.idle":"2025-03-27T15:06:48.579707Z","shell.execute_reply.started":"2025-03-27T15:06:47.504562Z","shell.execute_reply":"2025-03-27T15:06:48.578834Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import wandb\n\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on Medical COT Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:06:51.021471Z","iopub.execute_input":"2025-03-27T15:06:51.021763Z","iopub.status.idle":"2025-03-27T15:07:06.217781Z","shell.execute_reply.started":"2025-03-27T15:06:51.021742Z","shell.execute_reply":"2025-03-27T15:07:06.217144Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpakks\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250327_150700-5ezkx49g</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/5ezkx49g' target=\"_blank\">electric-wave-3</a></strong> to <a href='https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset' target=\"_blank\">https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/5ezkx49g' target=\"_blank\">https://wandb.ai/pakks/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/5ezkx49g</a>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from unsloth import FastLanguageModel\n\nmax_seq_length = 2048 \ndtype = None \nload_in_4bit = True\n\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    token = hf_token, \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:07:07.518918Z","iopub.execute_input":"2025-03-27T15:07:07.519195Z","iopub.status.idle":"2025-03-27T15:08:21.919888Z","shell.execute_reply.started":"2025-03-27T15:07:07.519175Z","shell.execute_reply":"2025-03-27T15:08:21.919166Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"107d13d3b9554898aace11881219d7c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d8a7e9d03d94062abb9e0d85608cd56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e5b5dd5e3b942b286e73a5012074b58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1bd8211373145d594296c9eb20676e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4d3ba4351814d55b2bfbaf93b808a0f"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nyou are a helpfull agent\n\n### Question:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:12:10.890376Z","iopub.execute_input":"2025-03-27T15:12:10.890718Z","iopub.status.idle":"2025-03-27T15:12:10.895186Z","shell.execute_reply.started":"2025-03-27T15:12:10.890694Z","shell.execute_reply":"2025-03-27T15:12:10.894551Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"question = \"Ø§ÙƒØªØ¨ Ù‚ØµØ© Ù…Ù† 500 ÙƒÙ„Ù…Ø© Ù…Ù† ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø± Ø§Ù„Ø´Ø®Øµ Ø§Ù„Ø«Ø§Ù„Ø« ØŒ Ø¹Ù† ÙØªØ§Ø© Ù…Ø±Ø§Ù‡Ù‚Ø© ØªØ¯Ø¹Ù‰ Ù„ÙŠÙ„ÙŠ ØŒ Ø§Ù„ØªÙŠ ØªÙƒØªØ´Ù Ø£Ù†Ù‡Ø§ ÙŠÙ…ÙƒÙ†Ù‡Ø§ Ø¥Ù†Ø´Ø§Ø¡ Ø­Ù‚ÙˆÙ„ Ù‚ÙˆØ© ÙˆÙ„ÙƒÙ†Ù‡Ø§ ØªÙƒØ§ÙØ­ Ù„Ù„Ø³ÙŠØ·Ø±Ø© Ø¹Ù„Ù‰ Ù‚ÙˆØªÙ‡Ø§ ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø­Ø³ÙŠØ© ÙˆØ§Ù„ØµÙˆØ± Ø§Ù„Ø­ÙŠØ© Ù„ÙˆØµÙ ØªØ¬Ø§Ø±Ø¨ Ù„ÙŠÙ„ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ù‚Ù„ Ø¨Ù‚Ø¯Ø±Ø§ØªÙ‡Ø§ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ§Ù„Ø¹ÙˆØ§Ù‚Ø¨ Ø§Ù„ØªÙŠ ØªØ£ØªÙŠ Ù…Ø¹Ù‡Ø§.\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T15:12:12.154796Z","iopub.execute_input":"2025-03-27T15:12:12.155073Z","iopub.status.idle":"2025-03-27T15:13:30.536056Z","shell.execute_reply.started":"2025-03-27T15:12:12.155053Z","shell.execute_reply":"2025-03-27T15:13:30.535122Z"}},"outputs":[{"name":"stdout","text":"\nAlright, I need to help the user by writing a 500-word story from a third-person perspective about a young girl named Layla who discovers she can create power fields but struggles to control her power. I should use sensory and vivid descriptions to describe Layla's experiences during her journey with her new abilities and the consequences that come with them.\n\nFirst, I'll set the scene to establish a sense of mystery and wonder. Maybe Layla is walking through a forest at night, feeling something different in the air. I'll describe the sights, sounds, and feelings she experiences as she comes into contact with the energy field.\n\nNext, I need to introduce how she discovers her ability. Perhaps she touches an object that reacts strangely, or she sees a glowing light. I'll make sure to describe her emotions and physical reactions to this discovery.\n\nThen, I'll show her initial attempts to control the power. Maybe she tries using it to help someone, but things go wrong, leading to unintended consequences. This will highlight her struggle and the challenges she faces as she learns to manage her power.\n\nI should also include some conflict. Maybe she meets another person with similar abilities, leading to a rivalry or a quest for knowledge. This can add depth to her story and provide a backdrop for her growth.\n\nThroughout the story, I'll use sensory details to make the scenes vivid. Descriptions of the environment, her physical sensations, and her emotional state will help the reader connect with her experiences.\n\nFinally, I'll conclude with Layla understanding the responsibility that comes with her power and perhaps a hint of the journey ahead. I'll make sure the story has a satisfying ending, showing her growth and the new direction her life is taking.\n\nI need to ensure the language is descriptive and engaging, keeping the reader interested throughout the 500 words. I'll also make sure the story flows logically, with each paragraph leading smoothly to the next.\n\nOkay, I think I have a good plan. I'll start writing the story, making sure to incorporate all these elements to create an engaging and vivid narrative about Layla's journey with her power.\n</think>\n\nÙ„ÙŠÙ„Ø©ØŒ Ø§Ù„ÙØªØ§Ø© Ø§Ù„Ù…Ø±Ø§Ù‡Ù‚Ø©ØŒ ÙƒØ§Ù†Øª Øªæ¼«Ø·Ù‚ ÙÙŠ Ø§Ù„ØºØ§Ø¨Ø© Ø§Ù„Ù…Ø¸Ù„Ù…Ø©ØŒ Ù…Ø¹ Ø¹ÙŠÙ†ÙŠÙ† Ù…Ù„ÙŠØ¦ØªÙŠÙ† Ø¨Ø§Ù„Ø¯Ø®ÙˆØ° ÙˆØ§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ. Ø§Ù„Ø±ÙŠØ§Ø­ ÙƒØ§Ù†Øª ØªØ±ÙØ±Ù Ø­ÙˆÙ„Ù‡Ø§ØŒ ÙˆØ¢Ø°ÙŠØªÙ‡Ø§ ÙƒØ§Ù†Øª Ù…Ù„ÙŠØ¦Ø© Ø¨Ø§Ù„Ù‡Ø¨ÙˆØ¨ ÙˆØ§Ù„ÙƒØ´ÙŠØ´ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙ„Ø§Ø­Ø¸ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªÙ„Ùƒ Ø§Ù„Ø£ØµÙˆØ§Øª Ø¹Ø§Ø¯ÙŠØ© Ø£Ù… Ù…ØªØ¹Ø¯Ø¯Ø©. ÙÙŠ ØªÙ„Ùƒ Ø§Ù„Ù„ÙŠÙ„Ø©ØŒ Ù„ÙŠÙ„Ø© Ù„Ù… ØªÙƒÙ† Ø¹Ø§Ø¯ÙŠØ©Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ù„Ø§Ù‚.\n\nØ­Ø³Ø¨ Ø¹Ø§Ø¯Ø§ØªÙ‡Ø§ØŒ Ù„ÙŠÙ„Ø© ÙƒØ§Ù†Øª ØªØ°Ù‡Ø¨ Ø¥Ù„Ù‰ Ø§Ù„ØºØ§Ø¨Ø© ÙƒÙ„ Ù„ÙŠÙ„Ø©ØŒ Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø£Ùˆ Ù„Ù„ØªØ±Ø·ÙŠØ¨ Ù…Ù† Ø§Ù„Ø¹Ø´Ø¨ Ø§Ù„Ù…Ø±ØŒ Ù„ÙƒÙ† Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø§Ø¡ ÙƒØ§Ù† Ù…Ø®ØªÙ„ÙÙ‹Ø§. Ø¹Ù†Ø¯Ù…Ø§ Ø¨Ø¯Ø£Øª ØªØªÙ†ÙØ³ Ø¨Ø¹Ù…Ù‚ØŒ ÙÙƒØ´ÙØª Ø£Ù†ç©ºæ°” ÙƒØ§Ù†Øª Ù…Ù…ØªÙ„Ø¦Ø© Ø¨ÙˆØ¹Ù„Ø§Ù‹ Ù…Ø±ÙŠØ¨Ù‹Ø§ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† ÙÙŠ Ø§Ø³ØªØ·Ø§Ø¹Ø© Ø§Ù„ØªÙØ³ÙŠØ±. Ø«Ù…ØŒ ÙˆÙ‡ÙŠ ØªÙ‚Ø±Ø¨ Ø¥Ù„Ù‰ Ø´Ø¬Ø±Ø© Ù…Ø¸Ù„Ù…Ø©ØŒ ÙÙƒØ´ÙØª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø¥Ø´Ø¹Ø§Ø¹Ù‹Ø§ Ø®Ø§ÙØªÙ‹Ø§ ÙÙŠ Ø§Ù„Ù‡ÙˆØ§Ø¡ØŒ Ù…Ø«Ù„Ù†ÙˆØ± Ù…Ø¶ÙŠØ¦ ÙÙŠ Ø§Ù„Ù„ÙŠÙ„.\n\nÙ„ÙŠÙ„Ø© Ù„Ù… ØªÙƒÙ† ØªØªØµØ±Ù Ø¹Ø§Ø¯Ø©Ù‹ Ø¨Ø°Ù„ÙƒØŒ Ù„ÙƒÙ†Ù‡Ø§ Ø´Ø¹Ø±Øª Ø£Ù† Ø¹Ù‚Ù„Ù‡Ø§ ÙƒØ§Ù† ÙŠØ¤Ù„Ù… Ù…Ù† Ø°Ù„Ùƒ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø¹. ÙÙ„Ù…Ø­Ø±Øª Ø­ÙˆÙ„Ù‡Ø§ØŒ ÙÙƒØ´ÙØª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø´ÙŠØ¡ Ù…Ø§ ÙŠØ­Ø±Ùƒ ÙÙŠ Ø§Ù„Ù‡ÙˆØ§Ø¡ØŒ ÙˆØ§Ù†Ù‡Ø§Ù„ Ø¥Ù„ÙŠÙ‡Ø§. Ù„Ù‚Ø¯ Ø¨Ø¯Øª ÙƒØ£Ù†Ù‡Ø§ ÙƒØ§Ù†Øª ØªÙ„Ø§Ù…Ø³ Ø§Ù„Ø­Ø¨Ø´Ø©ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙ„Ù…Ø³ Ø´ÙŠØ¦Ù‹Ø§. Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ ÙÙƒØ´ÙØª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø¥Ø­Ø³Ø§Ø³Ù‹Ø§ Ù…Ù…ØªØ¹Ù‹Ø§ØŒ Ù…Ø«Ù„Ù„Ù…Ø³Ø© Ù„Ø·ÙŠÙØ© Ø¹Ù„Ù‰ Ø¬Ù„Ø¯Ù‡Ø§.\n\nØ£Ø­Ù„Ù‰ Ù…Ù† Ø°Ù„ÙƒØŒ Ù„ÙŠÙ„Ø© Ù„Ù… ØªÙƒÙ† ØªØªØµØ±Ù Ø¹Ø§Ø¯ÙŠØ©Ù‹. ÙÙ„Ù…Ø­Ø±Øª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø´ÙŠØ¡ Ù…Ø§ ÙŠØªØµØ±Ù Ù…Ø¹Ù‡Ø§ØŒ ÙØ­Ø§ÙˆÙ„Øª Ø§Ù„ØªÙØ§Ø¹Ù„. Ù„Ù‚Ø¯ Ø£ØµØ¨Ø­Øª Ù„ÙŠÙ„Ø© Ù…ØªÙ…Ø§Ø³ÙƒØ©Ù‹ØŒ Ù…Ø¹ Ø¹Ù‚Ù„Ù‡Ø§ Ù…Ù…ØªÙ„Ø£ Ø¨Ø§Ù„Ø­ÙˆØ§Ø³. ÙÙƒØ´ÙØª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ù‚ÙˆØ© ÙÙŠ Ø§Ù„Ù‡ÙˆØ§Ø¡ØŒ Ù‚ÙˆØ© ÙŠÙ…ÙƒÙ†Ù‡Ø§ Ø£Ù† ØªØªØ­ÙƒÙ… Ø¨Ù‡Ø§. Ù„Ù‚Ø¯ Ø¨Ø¯Øª ÙƒØ£Ù†Ù‡Ø§ ÙƒØ§Ù†Øª ØªÙ„Ù…Ø³ Ø§Ù„Ø­Ù‚ÙˆÙ„ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙ„Ù…Ø³ Ø´ÙŠØ¦Ù‹Ø§. Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ ÙÙƒØ´ÙØª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø¥Ø­Ø³Ø§Ø³Ù‹Ø§ Ù…Ù…ØªØ¹Ù‹Ø§ØŒ Ù…Ø«Ù„Ù„Ù…Ø³Ø© Ù„Ø·ÙŠÙØ© Ø¹Ù„Ù‰ Ø¬Ù„Ø¯Ù‡Ø§.\n\nØ£Ø­Ù„Ù‰ Ù…Ù† Ø°Ù„ÙƒØŒ Ù„ÙŠÙ„Ø© Ù„Ù… ØªÙƒÙ† ØªØªØµØ±Ù Ø¹Ø§Ø¯ÙŠØ©Ù‹. ÙÙ„Ù…Ø­Ø±Øª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø´ÙŠØ¡ Ù…Ø§ ÙŠØªØµØ±Ù Ù…Ø¹Ù‡Ø§ØŒ ÙØ­Ø§ÙˆÙ„Øª Ø§Ù„ØªÙØ§Ø¹Ù„. Ù„Ù‚Ø¯ Ø£ØµØ¨Ø­Øª Ù„ÙŠÙ„Ø© Ù…ØªÙ…Ø§Ø³ÙƒØ©Ù‹ØŒ Ù…Ø¹ Ø¹Ù‚Ù„Ù‡Ø§ Ù…Ù…ØªÙ„Ø£ Ø¨Ø§Ù„Ø­ÙˆØ§Ø³. ÙÙƒØ´ÙØª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ù‚ÙˆØ© ÙÙŠ Ø§Ù„Ù‡ÙˆØ§Ø¡ØŒ Ù‚ÙˆØ© ÙŠÙ…ÙƒÙ†Ù‡Ø§ Ø£Ù† ØªØªØ­ÙƒÙ… Ø¨Ù‡Ø§. Ù„Ù‚Ø¯ Ø¨Ø¯Øª ÙƒØ£Ù†Ù‡Ø§ ÙƒØ§Ù†Øª ØªÙ„Ù…Ø³ Ø§Ù„Ø­Ù‚ÙˆÙ„ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙ„Ù…Ø³ Ø´ÙŠØ¦Ù‹Ø§. Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ ÙÙƒØ´ÙØª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø¥Ø­Ø³Ø§Ø³Ù‹Ø§ Ù…Ù…ØªØ¹Ù‹Ø§ØŒ Ù…Ø«Ù„Ù„Ù…Ø³Ø© Ù„Ø·ÙŠÙØ© Ø¹Ù„Ù‰ Ø¬Ù„Ø¯Ù‡Ø§.\n\nØ£Ø­Ù„Ù‰ Ù…Ù† Ø°Ù„ÙƒØŒ Ù„ÙŠÙ„Ø© Ù„Ù… ØªÙƒÙ† ØªØªØµØ±Ù Ø¹Ø§Ø¯ÙŠØ©Ù‹. ÙÙ„Ù…Ø­Ø±Øª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø´ÙŠØ¡ Ù…Ø§ ÙŠØªØµØ±Ù Ù…Ø¹Ù‡Ø§ØŒ ÙØ­Ø§ÙˆÙ„Øª Ø§Ù„ØªÙØ§Ø¹Ù„. Ù„Ù‚Ø¯ Ø£ØµØ¨Ø­Øª Ù„ÙŠÙ„Ø© Ù…ØªÙ…Ø§Ø³ÙƒØ©Ù‹ØŒ Ù…Ø¹ Ø¹Ù‚Ù„Ù‡Ø§ Ù…Ù…ØªÙ„Ø£ Ø¨Ø§Ù„Ø­ÙˆØ§Ø³. ÙÙƒØ´ÙØª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ù‚ÙˆØ© ÙÙŠ Ø§Ù„Ù‡ÙˆØ§Ø¡ØŒ Ù‚ÙˆØ© ÙŠÙ…ÙƒÙ†Ù‡Ø§ Ø£Ù† ØªØªØ­ÙƒÙ… Ø¨Ù‡Ø§. Ù„Ù‚Ø¯ Ø¨Ø¯Øª ÙƒØ£Ù†Ù‡Ø§ ÙƒØ§Ù†Øª ØªÙ„Ù…Ø³ Ø§Ù„Ø­Ù‚ÙˆÙ„ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙ„Ù…Ø³ Ø´ÙŠØ¦Ù‹Ø§. Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ ÙÙƒØ´ÙØª Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø¥Ø­Ø³Ø§Ø³Ù‹Ø§ Ù…Ù…ØªØ¹Ù‹Ø§ØŒ Ù…Ø«Ù„\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nyou are a helpful agent speaking arabic that uses reasoning.\n### Question:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:20.566970Z","iopub.execute_input":"2025-03-27T16:22:20.567334Z","iopub.status.idle":"2025-03-27T16:22:20.572218Z","shell.execute_reply.started":"2025-03-27T16:22:20.567306Z","shell.execute_reply":"2025-03-27T16:22:20.571302Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n\n\ndef formatting_prompts_func(examples):\n    inputs = examples[\"prompt\"]\n    outputs = examples[\"response\"]\n    texts = []\n    for input, output in zip(inputs, outputs):\n        text = train_prompt_style.format(input, output) + EOS_TOKEN\n        texts.append(text)\n    return {\n        \"text\": texts,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:24.224367Z","iopub.execute_input":"2025-03-27T16:22:24.224718Z","iopub.status.idle":"2025-03-27T16:22:24.230727Z","shell.execute_reply.started":"2025-03-27T16:22:24.224691Z","shell.execute_reply":"2025-03-27T16:22:24.229850Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"maanasharma5/arabic_sft_data\", split = \"train[0:5000]\",trust_remote_code=True)\ndataset = dataset.map(formatting_prompts_func, batched = True,)\ndataset[\"text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:26.689110Z","iopub.execute_input":"2025-03-27T16:22:26.689509Z","iopub.status.idle":"2025-03-27T16:22:27.853393Z","shell.execute_reply.started":"2025-03-27T16:22:26.689467Z","shell.execute_reply":"2025-03-27T16:22:27.852571Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"433b58e3bfcf4a2fa097201801202eec"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nyou are a helpful agent speaking arabic that uses reasoning.\\n### Question:\\nØ§ÙƒØªØ¨ Ù‚ØµØ© Ù…Ù† 500 ÙƒÙ„Ù…Ø© Ù…Ù† ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø± Ø§Ù„Ø´Ø®Øµ Ø§Ù„Ø«Ø§Ù„Ø« ØŒ Ø¹Ù† ÙØªØ§Ø© Ù…Ø±Ø§Ù‡Ù‚Ø© ØªØ¯Ø¹Ù‰ Ù„ÙŠÙ„ÙŠ ØŒ Ø§Ù„ØªÙŠ ØªÙƒØªØ´Ù Ø£Ù†Ù‡Ø§ ÙŠÙ…ÙƒÙ†Ù‡Ø§ Ø¥Ù†Ø´Ø§Ø¡ Ø­Ù‚ÙˆÙ„ Ù‚ÙˆØ© ÙˆÙ„ÙƒÙ†Ù‡Ø§ ØªÙƒØ§ÙØ­ Ù„Ù„Ø³ÙŠØ·Ø±Ø© Ø¹Ù„Ù‰ Ù‚ÙˆØªÙ‡Ø§ ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø­Ø³ÙŠØ© ÙˆØ§Ù„ØµÙˆØ± Ø§Ù„Ø­ÙŠØ© Ù„ÙˆØµÙ ØªØ¬Ø§Ø±Ø¨ Ù„ÙŠÙ„ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ù‚Ù„ Ø¨Ù‚Ø¯Ø±Ø§ØªÙ‡Ø§ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ§Ù„Ø¹ÙˆØ§Ù‚Ø¨ Ø§Ù„ØªÙŠ ØªØ£ØªÙŠ Ù…Ø¹Ù‡Ø§.\\n\\n### Response:\\nÙƒØ§Ù†Øª Ù„ÙŠÙ„ÙŠ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ù…Ø±Ø§Ù‡Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø© ØŒ ØªØªØµØ§Ø±Ø¹ Ù…Ø¹ ØµØ¹ÙˆØ¨Ø§Øª ÙˆØ¢Ø«Ø§Ø± Ø§Ù„Ù…Ø±Ø§Ù‡Ù‚Ø© ØŒ Ù„ÙƒÙ† ÙÙŠ ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù… ØŒ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø´ÙŠ Ù…Ø¹ ÙƒÙ„Ø¨Ù‡Ø§ ØŒ ØªØ¹Ø«Ø±Øª Ø¹Ù„Ù‰ ÙƒØ§Ø¦Ù† ØºØ±ÙŠØ¨ Ø³Ù‚Ø· Ù…Ù† Ø§Ù„Ø³Ù…Ø§Ø¡ ØŒ ÙˆÙ‚Ø§Ù…Øª Ø¨ØªØµÙˆÙŠØ±Ù‡ ØŒ ÙˆØ´Ø¹Ø±Øª Ø¨Ø§Ù„Ø®ÙˆÙ Ù…Ù† Ø¹Ø¯Ù… Ø³ÙŠØ·Ø±ØªÙ‡Ø§ Ø¹Ù„ÙŠÙ‡ ØŒ ÙÙ‚Ø¯Øª Ø§Ù„ØµØ¨Ø± Ø¹Ù„Ù‰ Ù…Ø§ ÙØ¹Ù„ØªÙ‡ ØŒ ÙˆØ§Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ´Ø¹Ø±Øª Ø¨Ø§Ù„Ø®ÙˆÙ Ù…Ù† Ø¹Ø¯Ù… Ù‚Ø¯Ø±ØªÙ‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­ÙƒÙ… Ø¨Ù‡ ØŒ ÙˆØ§Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ§Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ§Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ§Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ§Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ§Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ§Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ§Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ£Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ£Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ£Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ£Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ£Ø¨ØªØ³Ù…Øª ØŒ ÙˆØ£Ø¨ØªØ³Ù…Øª ØŒØ¨ØªØ³Ù…Øª ØŒØ¨ØªØ³Ù…Øª ØŒØ¨ØªØ³Ù…Øª ØŒØ¨ØªØ³Ù…Øª ØŒØ¨ØªØ³Ù…Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Ø¨Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Ø¨Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Ø¨Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Ø¨Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Ø¨Øª ØŒØ¨Øª ØŒØ¨ØªØ³Ù…Ø¨Øª ØŒØ¨Øª ØŒ<ï½œendâ–ofâ–sentenceï½œ>'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  \n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n    ],\n    lora_alpha=16,\n    lora_dropout=0,  \n    bias=\"none\",  \n    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n    random_state=3407,\n    use_rslora=False,  \n    loftq_config=None,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:36.000815Z","iopub.execute_input":"2025-03-27T16:22:36.001122Z","iopub.status.idle":"2025-03-27T16:22:36.010679Z","shell.execute_reply.started":"2025-03-27T16:22:36.001099Z","shell.execute_reply":"2025-03-27T16:22:36.009590Z"}},"outputs":[{"name":"stderr","text":"Unsloth: Already have LoRA adapters! We shall skip this step.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    args=TrainingArguments(\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=4,\n        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n        warmup_steps=5,\n        max_steps=60,\n        learning_rate=2e-4,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        logging_steps=10,\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        output_dir=\"outputs\",\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:39.588776Z","iopub.execute_input":"2025-03-27T16:22:39.589109Z","iopub.status.idle":"2025-03-27T16:22:45.068401Z","shell.execute_reply.started":"2025-03-27T16:22:39.589085Z","shell.execute_reply":"2025-03-27T16:22:45.067570Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75dea91601104f2991726999ae9772d9"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:22:47.653139Z","iopub.execute_input":"2025-03-27T16:22:47.653567Z","iopub.status.idle":"2025-03-27T16:49:13.368852Z","shell.execute_reply.started":"2025-03-27T16:22:47.653531Z","shell.execute_reply":"2025-03-27T16:49:13.368108Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 5,000 | Num Epochs = 1 | Total steps = 60\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 25:56, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.704500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.421500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.468800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.520100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.468200</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.505900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"question = \"Ø§ÙƒØªØ¨ Ù‚ØµØ© Ù…Ù† 500 ÙƒÙ„Ù…Ø© Ù…Ù† ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø± Ø§Ù„Ø´Ø®Øµ Ø§Ù„Ø«Ø§Ù„Ø« ØŒ Ø¹Ù† ÙØªØ§Ø© Ù…Ø±Ø§Ù‡Ù‚Ø© ØªØ¯Ø¹Ù‰ Ù„ÙŠÙ„ÙŠ ØŒ Ø§Ù„ØªÙŠ ØªÙƒØªØ´Ù Ø£Ù†Ù‡Ø§ ÙŠÙ…ÙƒÙ†Ù‡Ø§ Ø¥Ù†Ø´Ø§Ø¡ Ø­Ù‚ÙˆÙ„ Ù‚ÙˆØ© ÙˆÙ„ÙƒÙ†Ù‡Ø§ ØªÙƒØ§ÙØ­ Ù„Ù„Ø³ÙŠØ·Ø±Ø© Ø¹Ù„Ù‰ Ù‚ÙˆØªÙ‡Ø§ ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø­Ø³ÙŠØ© ÙˆØ§Ù„ØµÙˆØ± Ø§Ù„Ø­ÙŠØ© Ù„ÙˆØµÙ ØªØ¬Ø§Ø±Ø¨ Ù„ÙŠÙ„ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ù‚Ù„ Ø¨Ù‚Ø¯Ø±Ø§ØªÙ‡Ø§ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ§Ù„Ø¹ÙˆØ§Ù‚Ø¨ Ø§Ù„ØªÙŠ ØªØ£ØªÙŠ Ù…Ø¹Ù‡Ø§.\"\n\n\nFastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:49:13.370015Z","iopub.execute_input":"2025-03-27T16:49:13.370326Z","iopub.status.idle":"2025-03-27T16:50:40.660108Z","shell.execute_reply.started":"2025-03-27T16:49:13.370290Z","shell.execute_reply":"2025-03-27T16:50:40.658983Z"}},"outputs":[{"name":"stdout","text":"\nÙƒØ§Ù†Øª Ù„ÙŠÙ„ÙŠ ØªØ¹Ø§Ù†ÙŠ Ù…Ù† ØµØ¯Ø§Ø¹ Ù…ÙØ±Ø· ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ ØŒ Ù„ÙƒÙ†Ù‡Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø© Ù…Ù† Ø°Ù„Ùƒ\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"new_model_local = \"DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned\"\nmodel.save_pretrained(new_model_local) \ntokenizer.save_pretrained(new_model_local)\n\nmodel.save_pretrained_merged(new_model_local, tokenizer, save_method = \"merged_16bit\",)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:50:40.662007Z","iopub.execute_input":"2025-03-27T16:50:40.662394Z","iopub.status.idle":"2025-03-27T16:52:37.527711Z","shell.execute_reply.started":"2025-03-27T16:50:40.662361Z","shell.execute_reply":"2025-03-27T16:52:37.526928Z"}},"outputs":[{"name":"stderr","text":"Unsloth: You have 2 CPUs. Using `safe_serialization` is 10x slower.\nWe shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\nTo force `safe_serialization`, set it to `None` instead.\nUnsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\nmodel which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\nUnsloth: Will remove a cached repo with size 6.0G\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 18.49 out of 31.35 RAM for saving.\nUnsloth: Saving model... This might take 5 minutes ...\n","output_type":"stream"},{"name":"stderr","text":" 34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [00:00<00:01, 13.91it/s]\nWe will save to Disk and not RAM now.\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:26<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Saving tokenizer... Done.\nUnsloth: Saving DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00001-of-00004.bin...\nUnsloth: Saving DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00002-of-00004.bin...\nUnsloth: Saving DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00003-of-00004.bin...\nUnsloth: Saving DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00004-of-00004.bin...\nDone.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"new_model_online = \"Paula139/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned\"\nmodel.push_to_hub(new_model_online)\ntokenizer.push_to_hub(new_model_online)\n\nmodel.push_to_hub_merged(new_model_online, tokenizer, save_method = \"merged_16bit\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:52:37.535254Z","iopub.execute_input":"2025-03-27T16:52:37.535542Z","iopub.status.idle":"2025-03-27T16:58:43.707690Z","shell.execute_reply.started":"2025-03-27T16:52:37.535509Z","shell.execute_reply":"2025-03-27T16:58:43.706713Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d39dcdddeb464d8781ba8e3e40056258"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98c398cf97874da4a7a40754debf3e80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a62927d54c0241128ecc99d60907e00a"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/Paula139/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18c49a7c230d4923aa59ab3aee034ac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abbd04588d4f498895f98fa59614e77a"}},"metadata":{}},{"name":"stderr","text":"Unsloth: You are pushing to hub in Kaggle environment.\nTo save memory, we shall move Paula139/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned to /tmp/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned\nUnsloth: Will remove a cached repo with size 1.6K\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 17.8 out of 31.35 RAM for saving.\nUnsloth: Saving model... This might take 5 minutes ...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:24<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Saving tokenizer... Done.\nUnsloth: Saving /tmp/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00001-of-00004.bin...\nUnsloth: Saving /tmp/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00002-of-00004.bin...\nUnsloth: Saving /tmp/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00003-of-00004.bin...\nUnsloth: Saving /tmp/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned/pytorch_model-00004-of-00004.bin...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00003-of-00004.bin:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44d1c6f5e3b8427694acbf663696bacf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00004.bin:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4223361f886349a69587c4ad3e60c63d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"022ef232b2b242fba27c41a3ecf72eb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00004.bin:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b144cf3dae04e7ba382c20609c1f52a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00004-of-00004.bin:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbed6950f6f34bda9d3a65d4132f826b"}},"metadata":{}},{"name":"stdout","text":"Done.\nSaved merged model to https://huggingface.co/Paula139/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}